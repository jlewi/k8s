{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF on GKE\n",
    "\n",
    "This notebook shows how to train [TensorFlow CNN Benchmarks](https://github.com/tensorflow/benchmarks) on GKE using [TfJobs](https://github.com/tensorflow/k8s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook you must have the following installed\n",
    "  * gcloud\n",
    "  * kubectl\n",
    "  * helm\n",
    "  * kubernetes python client library\n",
    "  \n",
    "There is a Docker image based on Datalab suitable for running this notebook.\n",
    "\n",
    "You can start that container as follows\n",
    "\n",
    "```\n",
    "docker run --name=gke-datalab -p \"127.0.0.1:8081:8080\" \\\n",
    "    -v \"${HOME}:/content/datalab/home\" \\\n",
    "    -v /var/run/docker.sock:/var/run/docker.sock -d  -e \"PROJECT_ID=\" \\\n",
    "    gcr.io/tf-on-k8s-dogfood/gke-datalab:v20171103-73616f0\n",
    "```\n",
    "  * You need to map in docker if you want tobuild docker images inside the container.\n",
    "  * Alternatively, you can set \"use_gcb\" to true in order to build the images using Google Container Builder\n",
    "  \n",
    "Additionally the [py package](https://github.com/tensorflow/k8s/tree/master/py) must be a top level package importable as py\n",
    "  * If you cloned [tensorflow/k8s](https://github.com/tensorflow/k8s) and are running this notebook in place the path with be configured automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Turn on autoreloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import a bunch of modules and set some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Assumes we are running inside the cloned repo.\n",
    "# Try to setup the path so we can import py as a top level package\n",
    "ROOT_DIR = os.path.abspath(os.path.join(\"../..\"))\n",
    "if os.path.exists(os.path.join(ROOT_DIR, \"py\")):\n",
    "  if not ROOT_DIR in sys.path:\n",
    "    sys.path.append(ROOT_DIR)\n",
    "  \n",
    "import kubernetes\n",
    "from kubernetes import client as k8s_client\n",
    "from kubernetes import config as k8s_config\n",
    "from kubernetes.client.rest import ApiException\n",
    "from kubernetes.client.models.v1_label_selector import V1LabelSelector\n",
    "import datetime\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient import errors\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from pprint import pprint\n",
    "try:\n",
    "  from py import build_and_push_image\n",
    "  from py import util\n",
    "except ImportError:\n",
    "  raise ImportError(\"Please ensure the py package in https://github.com/tensorflow/k8s is a top level package\")\n",
    "import StringIO\n",
    "import subprocess\n",
    "import urllib\n",
    "import urllib2\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "TF_JOB_GROUP = \"tensorflow.org\"\n",
    "TF_JOB_VERSION = \"v1alpha1\"\n",
    "TF_JOB_PLURAL = \"tfjobs\"\n",
    "TF_JOB_KIND = \"TfJob\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the notebook for your use\n",
    "Change the constants defined below.\n",
    "  1. Change **project** to a project you have access to.\n",
    "     * GKE should be enabled for that project\n",
    "  1. Change **data_dir** and **job_dir**\n",
    "     * Use a GCS bucket that you have access to\n",
    "     * Ensure the service account on your GKE cluster can read/write to this GCS bucket\n",
    "\n",
    "* Optional change the cluster name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:googleapiclient.discovery:URL being requested: GET https://www.googleapis.com/discovery/v1/apis/container/v1/rest\n"
     ]
    }
   ],
   "source": [
    "project=\"cloud-ml-dev\"\n",
    "zone=\"us-east1-d\"\n",
    "cluster_name=\"gke-tf-example\"\n",
    "registry = \"gcr.io/\" + project\n",
    "dataset_name = \"flowers\"\n",
    "data_dir = os.path.join(\"gs://cloud-ml-dev_jlewi/inception/data\", dataset_name)\n",
    "job_dirs = \"gs://cloud-ml-dev_jlewi/inception/jobs\"\n",
    "gke = discovery.build(\"container\", \"v1\")\n",
    "namespace = \"default\"\n",
    "\n",
    "# Whether to build containers using Google Container Builder.\n",
    "# Set to false it will build by shelling out to docker build.\n",
    "use_gcb = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GKE Cluster Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The instructions below create a **CPU** cluster\n",
    "* To create a GKE cluster with GPUs sign up for the [GKE GPU Alpha](https://goo.gl/forms/ef7eh2x00hV3hahx1)\n",
    "* To use GPUs set accelerator and accelerator_count\n",
    "* For a full list of cluster options see the [Cluster object](https://cloud.google.com/container-engine/reference/rest/v1/projects.zones.clusters#Cluster) \n",
    "  in the GKE API docs\n",
    "\n",
    "To use an existing GKE cluster call **configure_kubectl** but not **create_cluster**\n",
    "\n",
    "* The code below issues a GKE request to create the cluster by calling util.create_cluster\n",
    "  * util.create_cluster uses the GKE python client library\n",
    "* After creating the cluster we call util.configure_kubectl\n",
    "  * This configures your machine to talk to the K8s master of the newly created cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:googleapiclient.discovery:URL being requested: POST https://container.googleapis.com/v1/projects/cloud-ml-dev/zones/us-east1-d/clusters?alt=json\n",
      "INFO:root:Creating cluster; project=cloud-ml-dev, zone=us-east1-d, name=gke-tf-example\n",
      "ERROR:root:Exception occured creating cluster: <HttpError 409 when requesting https://container.googleapis.com/v1/projects/cloud-ml-dev/zones/us-east1-d/clusters?alt=json returned \"The resource \"projects/cloud-ml-dev/zones/us-east1-d/clusters/gke-tf-example\" already exists.\">, status: 409\n",
      "INFO:root:Configuring kubectl\n",
      "INFO:root:Running: gcloud --project=cloud-ml-dev container clusters --zone=us-east1-d get-credentials gke-tf-example \n",
      "cwd=None\n",
      "INFO:root:Subprocess output:\n",
      "Fetching cluster endpoint and auth data.\n",
      "kubeconfig entry generated for gke-tf-example.\n",
      "\n",
      "INFO:requests.packages.urllib3.connectionpool:Starting new HTTPS connection (1): accounts.google.com\n"
     ]
    }
   ],
   "source": [
    "reload(util)\n",
    "machine_type = \"n1-standard-8\"\n",
    "use_gpu = True\n",
    "if use_gpu:\n",
    "  accelerator = \"nvidia-tesla-k80\"\n",
    "  accelerator_count = 1\n",
    "else:\n",
    "  accelerator = None\n",
    "  accelerator_count = 0\n",
    "\n",
    "cluster_request = {\n",
    "    \"cluster\": {\n",
    "        \"name\": cluster_name,\n",
    "        \"description\": \"A GKE cluster for TF.\",\n",
    "        \"initialNodeCount\": 1,\n",
    "        \"nodeConfig\": {\n",
    "            \"machineType\": machine_type,\n",
    "            \"oauthScopes\": [\n",
    "              \"https://www.googleapis.com/auth/cloud-platform\",\n",
    "            ],\n",
    "        },\n",
    "        # TODO(jlewi): Stop pinning GKE version once 1.8 becomes the default. \n",
    "        \"initialClusterVersion\": \"1.8.1-gke.1\",\n",
    "    }\n",
    "}\n",
    "\n",
    "if bool(accelerator) != (accelerator_count > 0):\n",
    "    raise ValueError(\"If accelerator is set accelerator_count must be  > 0\")\n",
    "    \n",
    "if accelerator:\n",
    "  # TODO(jlewi): Stop enabling Alpha once GPUs make it out of Alpha\n",
    "  cluster_request[\"cluster\"][\"enableKubernetesAlpha\"] = True\n",
    "\n",
    "  cluster_request[\"cluster\"][\"nodeConfig\"][\"accelerators\"] = [\n",
    "      {\n",
    "        \"acceleratorCount\": accelerator_count,\n",
    "        \"acceleratorType\": accelerator,\n",
    "      },\n",
    "  ]\n",
    "util.create_cluster(gke, project, zone, cluster_request)\n",
    "\n",
    "util.configure_kubectl(project, zone, cluster_name)\n",
    "\n",
    "k8s_config.load_kube_config()\n",
    "\n",
    "# Create an API client object to talk to the K8s master.\n",
    "api_client = k8s_client.ApiClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the Operator\n",
    "\n",
    "* We need to deploy the [TfJob](https://github.com/tensorflow/k8s) custom resource on our K8s cluster\n",
    "* TfJob is deployed using the [helm](https://github.com/kubernetes/helm) package manager so first we need to setup helm on our cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Creating service account for tiller.\n",
      "INFO:root:Service account tiller already exists.\n",
      "INFO:root:Role binding for service account tiller already exists.\n",
      "INFO:root:Running: helm init --service-account=tiller \n",
      "cwd=None\n",
      "INFO:root:Subprocess output:\n",
      "$HELM_HOME has been configured at /root/.helm.\n",
      "Warning: Tiller is already installed in the cluster.\n",
      "(Use --client-only to suppress this message, or --upgrade to upgrade Tiller to the current version.)\n",
      "Happy Helming!\n",
      "\n",
      "INFO:root:GPUs detected in cluster.\n",
      "INFO:root:Install GPU Drivers.\n",
      "INFO:root:GPU driver daemon set has already been installed\n",
      "INFO:root:tiller is ready\n",
      "INFO:root:GPUs are available.\n"
     ]
    }
   ],
   "source": [
    "util.setup_cluster(api_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that helm is setup we can deploy the TfJob CRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running: helm install https://storage.googleapis.com/tf-on-k8s-dogfood-releases/latest/tf-job-operator-chart-latest.tgz -n tf-job --wait --replace --set rbac.install=true,cloud=gke \n",
      "cwd=None\n",
      "INFO:root:Subprocess output:\n",
      "NAME:   tf-job\n",
      "LAST DEPLOYED: Fri Nov  3 02:00:48 2017\n",
      "NAMESPACE: default\n",
      "STATUS: DEPLOYED\n",
      "\n",
      "RESOURCES:\n",
      "==> v1/Pod(related)\n",
      "NAME                             READY  STATUS   RESTARTS  AGE\n",
      "tf-job-operator-b4598cf8c-fkbc2  1/1    Running  0         2s\n",
      "\n",
      "==> v1/ConfigMap\n",
      "NAME                    DATA  AGE\n",
      "tf-job-operator-config  1     2s\n",
      "\n",
      "==> v1/ServiceAccount\n",
      "NAME             SECRETS  AGE\n",
      "tf-job-operator  1        2s\n",
      "\n",
      "==> v1beta1/ClusterRole\n",
      "NAME             AGE\n",
      "tf-job-operator  2s\n",
      "\n",
      "==> v1beta1/ClusterRoleBinding\n",
      "NAME             AGE\n",
      "tf-job-operator  2s\n",
      "\n",
      "==> v1beta1/Deployment\n",
      "NAME             DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE\n",
      "tf-job-operator  1        1        1           1          2s\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CHART=\"https://storage.googleapis.com/tf-on-k8s-dogfood-releases/latest/tf-job-operator-chart-latest.tgz\"\n",
    "util.run([\"helm\", \"install\", CHART, \"-n\", \"tf-job\", \"--wait\", \"--replace\", \"--set\", \"rbac.install=true,cloud=gke\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a TensorFlow program on K8s we need to package our code as Docker images.\n",
    "\n",
    "The [Dockerfile](https://github.com/jlewi/k8s/blob/73616f09f335defc92f9b20225c272862e92e32b/examples/tensorflow-models/Dockerfile.template) \n",
    "for this example starts with the published Docker images for TensorFlow ands \n",
    "the code for our TensorFlow program\n",
    "  * In this example we are using the CIFAR10 example in the [TensorFlow's model zoo](https://github.com/tensorflow/models)\n",
    "  * So our Dockerfile just clones that repo\n",
    "  * Using TF's Docker images ensures we start with a reliable TF environment \n",
    "\n",
    "We need to build separate Docker images for CPU and GPU versions of TensorFlow.\n",
    "  * **modes** controls whether we build images for CPU, GPU or both \n",
    "  * Our Dockerfile is a [Jinja2](http://jinja.pocoo.org/) template, so we can easily\n",
    "    build docker images based on different TensorFlow versions\n",
    "  \n",
    "The base images controls which version of TensorFlow we will use\n",
    "  * Change the base images if you want to use a different version.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_gpu=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:context_dir: /tmp/tmpTfJobSampleContentxtMhuIw6\n",
      "INFO:root:Running gcloud container builds submit /tmp/tmpTfJobSampleContentxtMhuIw6 --tag=gcr.io/cloud-ml-dev/tf-benchmarks-cpu:34c398d-dirty-ea58d17 --project=cloud-ml-dev\n",
      "INFO:root:Creating temporary tarball archive of 6 file(s) totalling 4.9 KiB before compression.\n",
      "INFO:root:Uploading tarball of [/tmp/tmpTfJobSampleContentxtMhuIw6] to [gs://cloud-ml-dev_cloudbuild/source/1512244559.02-4181c556c1d1423f8f6f423ecf0c2198.tgz]\n",
      "INFO:root:Created [https://cloudbuild.googleapis.com/v1/projects/cloud-ml-dev/builds/65b753a4-9658-4986-b01f-381018b1fe45].\n",
      "INFO:root:Logs are available at [https://console.cloud.google.com/gcr/builds/65b753a4-9658-4986-b01f-381018b1fe45?project=cloud-ml-dev].\n",
      "INFO:root:----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "INFO:root:starting build \"65b753a4-9658-4986-b01f-381018b1fe45\"\n",
      "INFO:root:\n",
      "INFO:root:FETCHSOURCE\n",
      "INFO:root:Fetching storage object: gs://cloud-ml-dev_cloudbuild/source/1512244559.02-4181c556c1d1423f8f6f423ecf0c2198.tgz#1512244560238367\n",
      "INFO:root:Copying gs://cloud-ml-dev_cloudbuild/source/1512244559.02-4181c556c1d1423f8f6f423ecf0c2198.tgz#1512244560238367...\n",
      "/ [1 files][  1.8 KiB/  1.8 KiB]\n",
      "INFO:root:Operation completed over 1 objects/1.8 KiB.\n",
      "INFO:root:BUILD\n",
      "INFO:root:Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "INFO:root:Sending build context to Docker daemon  11.26kB\n",
      "INFO:root:Step 1/7 : FROM tensorflow/tensorflow:nightly\n",
      "INFO:root:nightly: Pulling from tensorflow/tensorflow\n",
      "INFO:root:ae79f2514705: Pulling fs layer\n",
      "INFO:root:5ad56d5fc149: Pulling fs layer\n",
      "INFO:root:170e558760e8: Pulling fs layer\n",
      "INFO:root:395460e233f5: Pulling fs layer\n",
      "INFO:root:6f01dc62e444: Pulling fs layer\n",
      "INFO:root:c86256e69c07: Pulling fs layer\n",
      "INFO:root:e961ec3bc7aa: Pulling fs layer\n",
      "INFO:root:39e908b6a830: Pulling fs layer\n",
      "INFO:root:ce0aa056c4bb: Pulling fs layer\n",
      "INFO:root:7fbe55c82247: Pulling fs layer\n",
      "INFO:root:1b06df180a8a: Pulling fs layer\n",
      "INFO:root:5aa078fdccde: Pulling fs layer\n",
      "INFO:root:395460e233f5: Waiting\n",
      "INFO:root:6f01dc62e444: Waiting\n",
      "INFO:root:c86256e69c07: Waiting\n",
      "INFO:root:e961ec3bc7aa: Waiting\n",
      "INFO:root:39e908b6a830: Waiting\n",
      "INFO:root:ce0aa056c4bb: Waiting\n",
      "INFO:root:7fbe55c82247: Waiting\n",
      "INFO:root:1b06df180a8a: Waiting\n",
      "INFO:root:5aa078fdccde: Waiting\n",
      "INFO:root:5ad56d5fc149: Verifying Checksum\n",
      "INFO:root:5ad56d5fc149: Download complete\n",
      "INFO:root:170e558760e8: Verifying Checksum\n",
      "INFO:root:170e558760e8: Download complete\n",
      "INFO:root:395460e233f5: Verifying Checksum\n",
      "INFO:root:395460e233f5: Download complete\n",
      "INFO:root:6f01dc62e444: Verifying Checksum\n",
      "INFO:root:6f01dc62e444: Download complete\n",
      "INFO:root:e961ec3bc7aa: Verifying Checksum\n",
      "INFO:root:e961ec3bc7aa: Download complete\n",
      "INFO:root:ae79f2514705: Verifying Checksum\n",
      "INFO:root:ae79f2514705: Download complete\n",
      "INFO:root:ae79f2514705: Pull complete\n",
      "INFO:root:5ad56d5fc149: Pull complete\n",
      "INFO:root:170e558760e8: Pull complete\n",
      "INFO:root:395460e233f5: Pull complete\n",
      "INFO:root:c86256e69c07: Verifying Checksum\n",
      "INFO:root:c86256e69c07: Download complete\n",
      "INFO:root:ce0aa056c4bb: Verifying Checksum\n",
      "INFO:root:ce0aa056c4bb: Download complete\n",
      "INFO:root:7fbe55c82247: Verifying Checksum\n",
      "INFO:root:7fbe55c82247: Download complete\n",
      "INFO:root:1b06df180a8a: Verifying Checksum\n",
      "INFO:root:1b06df180a8a: Download complete\n",
      "INFO:root:5aa078fdccde: Verifying Checksum\n",
      "INFO:root:5aa078fdccde: Download complete\n",
      "INFO:root:39e908b6a830: Verifying Checksum\n",
      "INFO:root:39e908b6a830: Download complete\n",
      "INFO:root:6f01dc62e444: Pull complete\n",
      "INFO:root:c86256e69c07: Pull complete\n",
      "INFO:root:e961ec3bc7aa: Pull complete\n",
      "INFO:root:39e908b6a830: Pull complete\n",
      "INFO:root:ce0aa056c4bb: Pull complete\n",
      "INFO:root:7fbe55c82247: Pull complete\n",
      "INFO:root:1b06df180a8a: Pull complete\n",
      "INFO:root:5aa078fdccde: Pull complete\n",
      "INFO:root:Digest: sha256:5edc0446cc989ad75bc30631f89f20694fe5bf5226f665d47e5c7f35a3b18484\n",
      "INFO:root:Status: Downloaded newer image for tensorflow/tensorflow:nightly\n",
      "INFO:root:---> b0149155aa1a\n",
      "INFO:root:Step 2/7 : RUN apt-get update && apt-get install -y --no-install-recommends     ca-certificates     build-essential     git\n",
      "INFO:root:---> Running in a60c6c1bac44\n",
      "INFO:root:Get:1 http://security.ubuntu.com/ubuntu xenial-security InRelease [102 kB]\n",
      "INFO:root:Get:2 http://archive.ubuntu.com/ubuntu xenial InRelease [247 kB]\n",
      "INFO:root:Get:3 http://security.ubuntu.com/ubuntu xenial-security/universe Sources [53.1 kB]\n",
      "INFO:root:Get:4 http://security.ubuntu.com/ubuntu xenial-security/main amd64 Packages [505 kB]\n",
      "INFO:root:Get:5 http://security.ubuntu.com/ubuntu xenial-security/restricted amd64 Packages [12.9 kB]\n",
      "INFO:root:Get:6 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 Packages [229 kB]\n",
      "INFO:root:Get:7 http://security.ubuntu.com/ubuntu xenial-security/multiverse amd64 Packages [3479 B]\n",
      "INFO:root:Get:8 http://archive.ubuntu.com/ubuntu xenial-updates InRelease [102 kB]\n",
      "INFO:root:Get:9 http://archive.ubuntu.com/ubuntu xenial-backports InRelease [102 kB]\n",
      "INFO:root:Get:10 http://archive.ubuntu.com/ubuntu xenial/universe Sources [9802 kB]\n",
      "INFO:root:Get:11 http://archive.ubuntu.com/ubuntu xenial/main amd64 Packages [1558 kB]\n",
      "INFO:root:Get:12 http://archive.ubuntu.com/ubuntu xenial/restricted amd64 Packages [14.1 kB]\n",
      "INFO:root:Get:13 http://archive.ubuntu.com/ubuntu xenial/universe amd64 Packages [9827 kB]\n",
      "INFO:root:Get:14 http://archive.ubuntu.com/ubuntu xenial/multiverse amd64 Packages [176 kB]\n",
      "INFO:root:Get:15 http://archive.ubuntu.com/ubuntu xenial-updates/universe Sources [231 kB]\n",
      "INFO:root:Get:16 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 Packages [866 kB]\n",
      "INFO:root:Get:17 http://archive.ubuntu.com/ubuntu xenial-updates/restricted amd64 Packages [13.7 kB]\n",
      "INFO:root:Get:18 http://archive.ubuntu.com/ubuntu xenial-updates/universe amd64 Packages [719 kB]\n",
      "INFO:root:Get:19 http://archive.ubuntu.com/ubuntu xenial-updates/multiverse amd64 Packages [18.5 kB]\n",
      "INFO:root:Get:20 http://archive.ubuntu.com/ubuntu xenial-backports/main amd64 Packages [5174 B]\n",
      "INFO:root:Get:21 http://archive.ubuntu.com/ubuntu xenial-backports/universe amd64 Packages [7150 B]\n",
      "INFO:root:Fetched 24.6 MB in 3s (6828 kB/s)\n",
      "INFO:root:Reading package lists...\n",
      "INFO:root:Reading package lists...\n",
      "INFO:root:Building dependency tree...\n",
      "INFO:root:Reading state information...\n",
      "INFO:root:build-essential is already the newest version (12.1ubuntu2).\n",
      "INFO:root:ca-certificates is already the newest version (20170717~16.04.1).\n",
      "INFO:root:ca-certificates set to manually installed.\n",
      "INFO:root:Suggested packages:\n",
      "INFO:root:gettext-base git-daemon-run | git-daemon-sysvinit git-doc git-el git-email\n",
      "INFO:root:git-gui gitk gitweb git-arch git-cvs git-mediawiki git-svn\n",
      "INFO:root:Recommended packages:\n",
      "INFO:root:less ssh-client\n",
      "INFO:root:The following NEW packages will be installed:\n",
      "INFO:root:git git-man liberror-perl\n",
      "INFO:root:0 upgraded, 3 newly installed, 0 to remove and 28 not upgraded.\n",
      "INFO:root:Need to get 3857 kB of archives.\n",
      "INFO:root:After this operation, 25.6 MB of additional disk space will be used.\n",
      "INFO:root:Get:1 http://archive.ubuntu.com/ubuntu xenial/main amd64 liberror-perl all 0.17-1.2 [19.6 kB]\n",
      "INFO:root:Get:2 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 git-man all 1:2.7.4-0ubuntu1.3 [736 kB]\n",
      "INFO:root:Get:3 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 git amd64 1:2.7.4-0ubuntu1.3 [3102 kB]\n",
      "INFO:root:\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "INFO:root:\u001b[0mFetched 3857 kB in 1s (3433 kB/s)\n",
      "INFO:root:Selecting previously unselected package liberror-perl.\n",
      "(Reading database ... 13279 files and directories currently installed.)\n",
      "INFO:root:Preparing to unpack .../liberror-perl_0.17-1.2_all.deb ...\n",
      "INFO:root:Unpacking liberror-perl (0.17-1.2) ...\n",
      "INFO:root:Selecting previously unselected package git-man.\n",
      "INFO:root:Preparing to unpack .../git-man_1%3a2.7.4-0ubuntu1.3_all.deb ...\n",
      "INFO:root:Unpacking git-man (1:2.7.4-0ubuntu1.3) ...\n",
      "INFO:root:Selecting previously unselected package git.\n",
      "INFO:root:Preparing to unpack .../git_1%3a2.7.4-0ubuntu1.3_amd64.deb ...\n",
      "INFO:root:Unpacking git (1:2.7.4-0ubuntu1.3) ...\n",
      "INFO:root:Setting up liberror-perl (0.17-1.2) ...\n",
      "INFO:root:Setting up git-man (1:2.7.4-0ubuntu1.3) ...\n",
      "INFO:root:Setting up git (1:2.7.4-0ubuntu1.3) ...\n",
      "INFO:root:---> bba09c59ddf9\n",
      "INFO:root:Removing intermediate container a60c6c1bac44\n",
      "INFO:root:Step 3/7 : RUN mkdir -p /opt\n",
      "INFO:root:---> Running in 873886e5d626\n",
      "INFO:root:---> 9c931a7f9633\n",
      "INFO:root:Removing intermediate container 873886e5d626\n",
      "INFO:root:Step 4/7 : RUN git clone https://github.com/jlewi/benchmarks.git /opt/tf-benchmarks &&     cd /opt/tf-benchmarks &&     git checkout debug_cpu\n",
      "INFO:root:---> Running in d0126cc396e0\n",
      "INFO:root:\u001b[91mCloning into '/opt/tf-benchmarks'...\n",
      "INFO:root:\u001b[0m\u001b[91mSwitched to a new branch 'debug_cpu'\n",
      "INFO:root:\u001b[0mBranch debug_cpu set up to track remote branch debug_cpu from origin.\n",
      "INFO:root:---> d2121c42de77\n",
      "INFO:root:Removing intermediate container d0126cc396e0\n",
      "INFO:root:Step 5/7 : COPY launcher.py /opt\n",
      "INFO:root:---> c144e3fef8e7\n",
      "INFO:root:Removing intermediate container 83875ff6e12d\n",
      "INFO:root:Step 6/7 : RUN chmod u+x /opt/launcher.py\n",
      "INFO:root:---> Running in ff53cab86066\n",
      "INFO:root:---> 01e32454f512\n",
      "INFO:root:Removing intermediate container ff53cab86066\n",
      "INFO:root:Step 7/7 : ENTRYPOINT /opt/launcher.py\n",
      "INFO:root:---> Running in 99517c3c4bf7\n",
      "INFO:root:---> 00ff80515df6\n",
      "INFO:root:Removing intermediate container 99517c3c4bf7\n",
      "INFO:root:Successfully built 00ff80515df6\n",
      "INFO:root:Successfully tagged gcr.io/cloud-ml-dev/tf-benchmarks-cpu:34c398d-dirty-ea58d17\n",
      "INFO:root:PUSH\n",
      "INFO:root:Pushing gcr.io/cloud-ml-dev/tf-benchmarks-cpu:34c398d-dirty-ea58d17\n",
      "INFO:root:The push refers to a repository [gcr.io/cloud-ml-dev/tf-benchmarks-cpu]\n",
      "INFO:root:877fa26a5295: Preparing\n",
      "INFO:root:b7dd9e8d03b8: Preparing\n",
      "INFO:root:9f4b78b1d5f0: Preparing\n",
      "INFO:root:96e14ec56aa4: Preparing\n",
      "INFO:root:40870993a9b9: Preparing\n",
      "INFO:root:99487e4819f0: Preparing\n",
      "INFO:root:bda11c17ea24: Preparing\n",
      "INFO:root:e7e0d4088325: Preparing\n",
      "INFO:root:103c3d13f3e0: Preparing\n",
      "INFO:root:eccb248eaf03: Preparing\n",
      "INFO:root:8ef163ca741c: Preparing\n",
      "INFO:root:49907af65b0a: Preparing\n",
      "INFO:root:4589f96366e6: Preparing\n",
      "INFO:root:b97229212d30: Preparing\n",
      "INFO:root:cd181336f142: Preparing\n",
      "INFO:root:0f5ff0cf6a1c: Preparing\n",
      "INFO:root:99487e4819f0: Waiting\n",
      "INFO:root:bda11c17ea24: Waiting\n",
      "INFO:root:e7e0d4088325: Waiting\n",
      "INFO:root:103c3d13f3e0: Waiting\n",
      "INFO:root:eccb248eaf03: Waiting\n",
      "INFO:root:8ef163ca741c: Waiting\n",
      "INFO:root:49907af65b0a: Waiting\n",
      "INFO:root:4589f96366e6: Waiting\n",
      "INFO:root:b97229212d30: Waiting\n",
      "INFO:root:cd181336f142: Waiting\n",
      "INFO:root:0f5ff0cf6a1c: Waiting\n",
      "INFO:root:40870993a9b9: Layer already exists\n",
      "INFO:root:99487e4819f0: Layer already exists\n",
      "INFO:root:bda11c17ea24: Layer already exists\n",
      "INFO:root:b7dd9e8d03b8: Pushed\n",
      "INFO:root:877fa26a5295: Pushed\n",
      "INFO:root:9f4b78b1d5f0: Pushed\n",
      "INFO:root:eccb248eaf03: Layer already exists\n",
      "INFO:root:49907af65b0a: Layer already exists\n",
      "INFO:root:4589f96366e6: Layer already exists\n",
      "INFO:root:b97229212d30: Layer already exists\n",
      "INFO:root:96e14ec56aa4: Pushed\n",
      "INFO:root:cd181336f142: Layer already exists\n",
      "INFO:root:0f5ff0cf6a1c: Layer already exists\n",
      "INFO:root:e7e0d4088325: Pushed\n",
      "INFO:root:8ef163ca741c: Pushed\n",
      "INFO:root:103c3d13f3e0: Pushed\n",
      "INFO:root:34c398d-dirty-ea58d17: digest: sha256:f76e765d3314f39e21326caa58eeeea78d6c8b7386c478ae12858569bcd22f2a size: 3669\n",
      "INFO:root:DONE\n",
      "INFO:root:--------------------------------------------------------------------------------\n",
      "INFO:root:\n",
      "INFO:root:ID                                    CREATE_TIME                DURATION  SOURCE                                                                                  IMAGES                                                       STATUS\n",
      "INFO:root:65b753a4-9658-4986-b01f-381018b1fe45  2017-12-02T19:56:00+00:00  2M22S     gs://cloud-ml-dev_cloudbuild/source/1512244559.02-4181c556c1d1423f8f6f423ecf0c2198.tgz  gcr.io/cloud-ml-dev/tf-benchmarks-cpu:34c398d-dirty-ea58d17  SUCCESS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cpu': 'gcr.io/cloud-ml-dev/tf-benchmarks-cpu:34c398d-dirty-ea58d17'}\n"
     ]
    }
   ],
   "source": [
    "reload(build_and_push_image)\n",
    "# Set GCB project to build with GCB as opposed to locally using Docker.\n",
    "# Building on GCB can be much faster because we don't have to pull/push the images to our\n",
    "# local machine.\n",
    "gcb_project = project\n",
    "#gcb_project=None\n",
    "if use_gpu:\n",
    "  modes = [\"cpu\", \"gpu\"]\n",
    "else:\n",
    "  modes = [\"cpu\"]\n",
    "\n",
    "image = os.path.join(registry, \"tf-benchmarks\")\n",
    "dockerfile = os.path.join(ROOT_DIR, \"examples\", \"tf-benchmarks\", \"Dockerfile.template\")\n",
    "# base_images = {\n",
    "#   \"cpu\": \"gcr.io/tensorflow/tensorflow:1.4.0\",\n",
    "#   \"gpu\": \"gcr.io/tensorflow/tensorflow:1.4.0-gpu\",\n",
    "# }\n",
    "# tf_cnn_benchmarks is using some bleading edge code.\n",
    "# Nightly isn't in GCR;\n",
    "# https://pantheon.corp.google.com/gcr/images/tensorflow/GLOBAL/tensorflow?gcrImageListquery=%255B%255D&gcrImageListpage=%257B%2522t%2522%253A%2522%2522%252C%2522i%2522%253A0%257D&gcrImageListsize=50&gcrImageListsort=%255B%257B%2522p%2522%253A%2522uploaded%2522%252C%2522s%2522%253Afalse%257D%255D\n",
    "base_images = {\n",
    "   \"cpu\": \"tensorflow/tensorflow:nightly\",\n",
    "   \"gpu\": \"tensorflow/tensorflow:nightly-gpu\",\n",
    " }\n",
    "images = build_and_push_image.build_and_push(dockerfile, image, modes=modes, base_images=base_images,\n",
    "                                             project=gcb_project)\n",
    "print(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a TfJob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To submit a TfJob, we define a TfJob spec and then create it in our cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': 'gcr.io/cloud-ml-dev/tf-benchmarks-gpu:34c398d-dirty-244ca2d', 'cpu': 'gcr.io/cloud-ml-dev/tf-benchmarks-cpu:34c398d-dirty-a2f786d'}\n"
     ]
    }
   ],
   "source": [
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cpu': 'gcr.io/cloud-ml-dev/tf-benchmarks-cpu:34c398d-dirty-a68c476',\n",
       " 'gpu': 'gcr.io/cloud-ml-dev/tf-benchmarks-gpu:34c398d-dirty-7e7655c'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See https://stackoverflow.com/questions/21016220/is-it-possible-to-emit-valid-yaml-with-anchors-references-disabled-using-ruby\n",
    "import yaml\n",
    "\n",
    "class ExplicitDumper(yaml.SafeDumper):\n",
    "    \"\"\"\n",
    "    A dumper that will never emit aliases.\n",
    "    \"\"\"\n",
    "\n",
    "    def ignore_aliases(self, data):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: tensorflow.org/v1alpha1\n",
      "kind: TfJob\n",
      "metadata:\n",
      "  name: inception-171202-200326\n",
      "  namespace: default\n",
      "spec:\n",
      "  replicaSpecs:\n",
      "  - replicas: 1\n",
      "    template:\n",
      "      spec:\n",
      "        containers:\n",
      "        - args:\n",
      "          - python\n",
      "          - tf_cnn_benchmarks.py\n",
      "          - --batch_size=32\n",
      "          - --model=resnet50\n",
      "          - --variable_update=parameter_server\n",
      "          - --num_gpus=1\n",
      "          - --local_parameter_device=cpu\n",
      "          - --device=cpu\n",
      "          - --data_format=NHWC\n",
      "          image: gcr.io/cloud-ml-dev/tf-benchmarks-cpu:34c398d-dirty-ea58d17\n",
      "          name: tensorflow\n",
      "          workingDir: /opt/tf-benchmarks/scripts/tf_cnn_benchmarks\n",
      "        restartPolicy: OnFailure\n",
      "    tfReplicaType: MASTER\n",
      "  - replicas: 1\n",
      "    template:\n",
      "      spec:\n",
      "        containers:\n",
      "        - args:\n",
      "          - python\n",
      "          - tf_cnn_benchmarks.py\n",
      "          - --batch_size=32\n",
      "          - --model=resnet50\n",
      "          - --variable_update=parameter_server\n",
      "          - --num_gpus=1\n",
      "          - --local_parameter_device=cpu\n",
      "          - --device=cpu\n",
      "          - --data_format=NHWC\n",
      "          image: gcr.io/cloud-ml-dev/tf-benchmarks-cpu:34c398d-dirty-ea58d17\n",
      "          name: tensorflow\n",
      "          workingDir: /opt/tf-benchmarks/scripts/tf_cnn_benchmarks\n",
      "        restartPolicy: OnFailure\n",
      "    tfReplicaType: WORKER\n",
      "  - replicas: 1\n",
      "    template:\n",
      "      spec:\n",
      "        containers:\n",
      "        - args:\n",
      "          - python\n",
      "          - tf_cnn_benchmarks.py\n",
      "          - --batch_size=32\n",
      "          - --model=resnet50\n",
      "          - --variable_update=parameter_server\n",
      "          - --num_gpus=1\n",
      "          - --local_parameter_device=cpu\n",
      "          - --device=cpu\n",
      "          - --data_format=NHWC\n",
      "          image: gcr.io/cloud-ml-dev/tf-benchmarks-cpu:34c398d-dirty-ea58d17\n",
      "          name: tensorflow\n",
      "          workingDir: /opt/tf-benchmarks/scripts/tf_cnn_benchmarks\n",
      "        restartPolicy: OnFailure\n",
      "    tfReplicaType: PS\n",
      "  tfImage: gcr.io/cloud-ml-dev/tf-benchmarks-cpu:34c398d-dirty-ea58d17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Created job inception-171202-200326\n"
     ]
    }
   ],
   "source": [
    "use_gpu = False\n",
    "crd_api = k8s_client.CustomObjectsApi(api_client)\n",
    "\n",
    "namespace = \"default\"\n",
    "job_name = \"inception-\"+ datetime.datetime.now().strftime(\"%y%m%d-%H%M%S\")\n",
    "job_dir = os.path.join(job_dirs, job_name)\n",
    "num_steps = 10\n",
    "body = {}\n",
    "body['apiVersion'] = TF_JOB_GROUP + \"/\" + TF_JOB_VERSION\n",
    "body['kind'] = TF_JOB_KIND\n",
    "body['metadata'] = {}\n",
    "body['metadata']['name'] = job_name\n",
    "body['metadata']['namespace'] = namespace\n",
    "\n",
    "clone_on_cpu = not use_gpu\n",
    "\n",
    "# Need to convert unicode to string.\n",
    "for k, v in images.iteritems():\n",
    "  images[k] = str(v)\n",
    "\n",
    "body[\"spec\"] = {}\n",
    "body[\"spec\"][\"replicaSpecs\"] = []\n",
    "\n",
    "working_dir = \"/opt/tf-benchmarks/scripts/tf_cnn_benchmarks\"\n",
    "\n",
    "num_workers = 1\n",
    "num_ps = 1\n",
    "\n",
    "command = [\n",
    "   \"python\",\n",
    "   \"tf_cnn_benchmarks.py\",   \n",
    "   \"--batch_size=32\",\n",
    "   \"--model=resnet50\",\n",
    "   \"--variable_update=parameter_server\",   \n",
    "]\n",
    "\n",
    "if use_gpu:\n",
    "  command.append(\"--num_gpus=1\")\n",
    "else:\n",
    "  # We need to set num_gpus=1 even if not using GPUs because otherwise the devie list\n",
    "  # is empty because of this code\n",
    "  # https://github.com/tensorflow/benchmarks/blob/master/scripts/tf_cnn_benchmarks/benchmark_cnn.py#L775\n",
    "  command.append(\"--num_gpus=1\")\n",
    "  command.append(\"--local_parameter_device=cpu\")\n",
    "  command.append(\"--device=cpu\")\n",
    "  command.append(\"--data_format=NHWC\")\n",
    "    \n",
    "# Add the master spec.\n",
    "# The master only acts as the chief and doesn't do any training so it can always use the CPU image.\n",
    "master_spec = {\n",
    "  \"replicas\": 1,\n",
    "  \"tfReplicaType\": \"MASTER\",\n",
    "  \"template\": {\n",
    "    \"spec\": {\n",
    "      \"containers\": [\n",
    "        {\n",
    "          \"image\": images[\"cpu\"],\n",
    "          \"name\": \"tensorflow\",\n",
    "          \"workingDir\": working_dir,\n",
    "          \"args\": command,\n",
    "        }\n",
    "      ],\n",
    "      \"restartPolicy\": \"OnFailure\",\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "body[\"spec\"][\"replicaSpecs\"].append(master_spec)\n",
    "\n",
    "worker_image = images[\"cpu\"]\n",
    "if use_gpu:  \n",
    "  worker_image = images[\"gpu\"]\n",
    "  \n",
    "worker_spec = {\n",
    "  \"replicas\": num_workers,\n",
    "  \"tfReplicaType\": \"WORKER\",\n",
    "  \"template\": {\n",
    "    \"spec\": {\n",
    "      \"containers\": [\n",
    "        {\n",
    "          \"image\": worker_image,\n",
    "          \"name\": \"tensorflow\",\n",
    "          \"workingDir\": working_dir,          \n",
    "          \"args\": command,\n",
    "        }\n",
    "      ],\n",
    "      \"restartPolicy\": \"OnFailure\",\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "if use_gpu:\n",
    "  worker_spec[\"template\"][\"spec\"][\"containers\"][0][\"resources\"] = {\n",
    "    \"limits\": {\n",
    "      \"nvidia.com/gpu\": accelerator_count,\n",
    "    }    \n",
    "  }\n",
    "\n",
    "body[\"spec\"][\"replicaSpecs\"].append(worker_spec)\n",
    "\n",
    "ps_spec = {\n",
    "  \"replicas\": num_ps,\n",
    "  \"tfReplicaType\": \"PS\",  \n",
    "  \"template\": {\n",
    "    \"spec\": {\n",
    "      \"containers\": [\n",
    "        {\n",
    "          \"image\": images[\"cpu\"],\n",
    "          \"name\": \"tensorflow\",\n",
    "          \"workingDir\": working_dir,          \n",
    "          \"args\": command,\n",
    "        }\n",
    "      ],\n",
    "      \"restartPolicy\": \"OnFailure\",\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "body[\"spec\"][\"replicaSpecs\"].append(ps_spec)\n",
    "\n",
    "body[\"spec\"][\"tfImage\"] = images[\"cpu\"]\n",
    "# Tensorboard is crashing with TF 1.5\n",
    "# body[\"spec\"][\"tensorBoard\"] = {\n",
    "#   \"logDir\": job_dir\n",
    "# }\n",
    "\n",
    "import yaml\n",
    "print(yaml.dump(body, Dumper=ExplicitDumper, default_flow_style=False))\n",
    "\n",
    "try: \n",
    "    # Create a Resource\n",
    "    api_response = crd_api.create_namespaced_custom_object(TF_JOB_GROUP, TF_JOB_VERSION, namespace, TF_JOB_PLURAL, body) \n",
    "    logging.info(\"Created job %s\", api_response[\"metadata\"][\"name\"])\n",
    "except ApiException as e:\n",
    "    print(\n",
    "        \"Exception when calling DefaultApi->apis_fqdn_v1_namespaces_namespace_resource_post: %s\\n\" % \n",
    "        e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring your job and waiting for it to finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can monitor the job a number of ways\n",
    "  * We can poll K8s to get the status of the TfJob\n",
    "  * We can check the TensorFlow logs\n",
    "      * These are available in StackDriver\n",
    "  * We can access TensorBoard if the TfJob was configured to launch TensorBoard\n",
    "  \n",
    "Running the code below will poll K8s for the TfJob status and also print out relevant links for TensorBoard and the StackDriver logs\n",
    "\n",
    "To access TensorBoard you will need to run **kubectl proxy** to create a proxy connection to your K8s cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Job has runtime id: eg5k\n",
      "INFO:root:Tensorboard will be available at job\n",
      " http://127.0.0.1:8001/api/v1/proxy/namespaces/default/services/tensorboard-eg5k:80/\n",
      "INFO:root:master pod is master-eg5k-0-p85pk\n",
      "INFO:root:Logs will be available in stackdriver at\n",
      "https://console.cloud.google.com/logs/viewer?expandAll=false&dateRangeStart=2017-11-03T03%3A00%3A43%2B00%3A00&advancedFilter=resource.type%3D%22container%22%0Aresource.labels.namespace_id%3D%22default%22%0Aresource.labels.pod_id%3D%22master-eg5k-0-p85pk%22&interval=NO_LIMIT&project=cloud-ml-dev&logName=projects%2Fcloud-ml-dev%2Flogs%2Ftensorflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n",
      "Job status Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Job Succeeded\n"
     ]
    }
   ],
   "source": [
    "# Get pod logs\n",
    "v1 = k8s_client.CoreV1Api(api_client)\n",
    "\n",
    "k8s_config.load_kube_config()\n",
    "api_client = k8s_client.ApiClient()\n",
    "crd_api = k8s_client.CustomObjectsApi(api_client)\n",
    "\n",
    "master_started = False\n",
    "runtime_id = None\n",
    "while True:\n",
    "  results = crd_api.get_namespaced_custom_object(TF_JOB_GROUP, TF_JOB_VERSION, namespace, TF_JOB_PLURAL, job_name)\n",
    "\n",
    "  if not runtime_id:\n",
    "    runtime_id = results[\"spec\"][\"RuntimeId\"]\n",
    "    logging.info(\"Job has runtime id: %s\", runtime_id)\n",
    "    \n",
    "    tensorboard_url = \"http://127.0.0.1:8001/api/v1/proxy/namespaces/{namespace}/services/tensorboard-{runtime_id}:80/\".format(\n",
    "    namespace=namespace, runtime_id=runtime_id)\n",
    "    logging.info(\"Tensorboard will be available at job\\n %s\", tensorboard_url)\n",
    "\n",
    "  if not master_started:\n",
    "    # Get the master pod\n",
    "    # TODO(jlewi): V1LabelSelector doesn't seem to help\n",
    "    pods = v1.list_namespaced_pod(namespace=namespace, label_selector=\"runtime_id={0},job_type=MASTER\".format(runtime_id))\n",
    "\n",
    "    # TODO(jlewi): We should probably handle the case where more than 1 pod gets started.\n",
    "    # TODO(jlewi): Once GKE logs pod labels we can just filter by labels to get all logs for a particular task\n",
    "    # and not have to identify the actual pod.\n",
    "    if pods.items:\n",
    "      pod = pods.items[0]\n",
    "\n",
    "      logging.info(\"master pod is %s\", pod.metadata.name)\n",
    "      query={\n",
    "        'advancedFilter': 'resource.type=\"container\"\\nresource.labels.namespace_id=\"default\"\\nresource.labels.pod_id=\"{0}\"'.format(pod.metadata.name), \n",
    "        'dateRangeStart': pod.metadata.creation_timestamp.isoformat(),\n",
    "        'expandAll': 'false',\n",
    "        'interval': 'NO_LIMIT',\n",
    "        'logName': 'projects/{0}/logs/tensorflow'.format(project),\n",
    "       'project': project, \n",
    "      }\n",
    "      logging.info(\"Logs will be available in stackdriver at\\n\"\n",
    "                   \"https://console.cloud.google.com/logs/viewer?\" + urllib.urlencode(query))\n",
    "      master_started = True\n",
    "\n",
    "  if results[\"status\"][\"phase\"] == \"Done\":\n",
    "    break\n",
    "  print(\"Job status {0}\".format(results[\"status\"][\"phase\"]))\n",
    "  time.sleep(5)\n",
    "  \n",
    "logging.info(\"Job %s\", results[\"status\"][\"state\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "* Delete the GKE cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function delete_cluster in module py.util:\n",
      "\n",
      "delete_cluster(gke, name, project, zone)\n",
      "    Delete the cluster.\n",
      "    \n",
      "    Args:\n",
      "      gke: Client for GKE.\n",
      "      name: Name of the cluster.\n",
      "      project: Project that owns the cluster.\n",
      "      zone: Zone where the cluster is running.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "util.delete_cluster(gke, cluster_name, project, zone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:requests.packages.urllib3.connectionpool:Starting new HTTPS connection (1): accounts.google.com\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-9187b38024ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mapi_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk8s_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApiClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk8s_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoreV1Api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mruntime_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"spec\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"RuntimeId\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# TODO(jlewi): V1LabelSelector doesn't seem to help\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_namespaced_pod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_selector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"runtime_id={0},job_type=MASTER\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruntime_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "from kubernetes.client.models.v1_label_selector import V1LabelSelector\n",
    "import urllib2\n",
    "# Get pod logs\n",
    "k8s_config.load_kube_config()\n",
    "api_client = k8s_client.ApiClient()\n",
    "v1 = k8s_client.CoreV1Api(api_client)\n",
    "runtime_id = results[\"spec\"][\"RuntimeId\"]\n",
    "# TODO(jlewi): V1LabelSelector doesn't seem to help\n",
    "pods = v1.list_namespaced_pod(namespace=namespace, label_selector=\"runtime_id={0},job_type=MASTER\".format(runtime_id))\n",
    "\n",
    "pod = pods.items[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the Pod Logs From K8s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read pod logs directly from K8s and not depend on stackdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-27 23:37:29,807 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', error(104, 'Connection reset by peer'))': /api/v1/namespaces/default/pods/master-hrhh-0-wrh6g/log\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', error(104, 'Connection reset by peer'))': /api/v1/namespaces/default/pods/master-hrhh-0-wrh6g/log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'gs://cloud-ml-dev_jlewi/cifar10/jobs/cifar10-171027-174224', '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_session_config': gpu_options {\n",
      "  force_gpu_compatible: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_tf_random_seed': None, '_task_type': u'master', '_environment': u'cloud', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcb715c9b10>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_log_step_count_steps': 100}\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:269: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_1/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_2/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_3/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_4/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_5/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_6/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1/avg_pool/: (?, 16, 16, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_1/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_2/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_3/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_4/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_5/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_6/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1/avg_pool/: (?, 8, 8, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_1/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_2/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_3/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_4/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_5/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_6/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/global_avg_pool/: (?, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/fully_connected/: (?, 11)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "2017-10-27 17:42:51.299775: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-10-27 17:42:51.299827: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-10-27 17:42:51.299834: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-10-27 17:42:51.299839: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-10-27 17:42:51.299845: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into gs://cloud-ml-dev_jlewi/cifar10/jobs/cifar10-171027-174224/model.ckpt.\n",
      "INFO:tensorflow:loss = 4.74784, step = 1\n",
      "INFO:tensorflow:loss = 4.74784, learning_rate = 0.1\n",
      "INFO:tensorflow:Saving checkpoints for 10 into gs://cloud-ml-dev_jlewi/cifar10/jobs/cifar10-171027-174224/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 11.2765.\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_1/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_2/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_3/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_4/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_5/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_6/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1/avg_pool/: (?, 16, 16, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_1/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_2/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_3/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_4/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_5/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_6/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1/avg_pool/: (?, 8, 8, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_1/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_2/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_3/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_4/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_5/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_6/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/global_avg_pool/: (?, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/fully_connected/: (?, 11)\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-27-17:44:06\n",
      "INFO:tensorflow:Restoring parameters from gs://cloud-ml-dev_jlewi/cifar10/jobs/cifar10-171027-174224/model.ckpt-10\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-27-17:45:24\n",
      "INFO:tensorflow:Saving dict for global step 10: accuracy = 0.1, global_step = 10, loss = 2.26738e+20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ret = v1.read_namespaced_pod_log(namespace=namespace, name=pod.metadata.name)\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch Logs from StackDriver Programmatically\n",
    "  * On GKE pod logs are stored in stackdriver\n",
    "  * These logs will stick around longer than pod logs\n",
    "  * Fetching from stackNote this tends to be a little slow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined from the Cloud SDK configuration. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'gs://cloud-ml-dev_jlewi/cifar10/jobs/cifar10-171027-174224', '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_session_config': gpu_options {\n",
      "force_gpu_compatible: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_tf_random_seed': None, '_task_type': u'master', '_environment': u'cloud', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcb715c9b10>, '_tf_config': gpu_options {\n",
      "per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_log_step_count_steps': 100}\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:269: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_1/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_2/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_3/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_4/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_5/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_6/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1/avg_pool/: (?, 16, 16, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_1/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_2/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_3/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_4/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_5/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_6/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1/avg_pool/: (?, 8, 8, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_1/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_2/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_3/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_4/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_5/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_6/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/global_avg_pool/: (?, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/fully_connected/: (?, 11)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "2017-10-27 17:42:51.299775: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-10-27 17:42:51.299827: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-10-27 17:42:51.299834: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-10-27 17:42:51.299839: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-10-27 17:42:51.299845: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into gs://cloud-ml-dev_jlewi/cifar10/jobs/cifar10-171027-174224/model.ckpt.\n",
      "INFO:tensorflow:loss = 4.74784, step = 1\n",
      "INFO:tensorflow:loss = 4.74784, learning_rate = 0.1\n",
      "INFO:tensorflow:Saving checkpoints for 10 into gs://cloud-ml-dev_jlewi/cifar10/jobs/cifar10-171027-174224/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 11.2765.\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_1/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_2/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_3/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_4/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_5/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_6/: (?, 32, 32, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1/avg_pool/: (?, 16, 16, 16)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_1/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_2/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_3/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_4/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_5/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_6/: (?, 16, 16, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1/avg_pool/: (?, 8, 8, 32)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_1/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_2/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_3/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_4/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_5/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_6/: (?, 8, 8, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/global_avg_pool/: (?, 64)\n",
      "INFO:tensorflow:image after unit resnet/tower_0/fully_connected/: (?, 11)\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-27-17:44:06\n",
      "INFO:tensorflow:Restoring parameters from gs://cloud-ml-dev_jlewi/cifar10/jobs/cifar10-171027-174224/model.ckpt-10\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-27-17:45:24\n",
      "INFO:tensorflow:Saving dict for global step 10: accuracy = 0.1, global_step = 10, loss = 2.26738e+20\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import logging as gcp_logging\n",
    "pod_filter = 'resource.type=\"container\" AND resource.labels.pod_id=\"master-hrhh-0-wrh6g\"'\n",
    "client = gcp_logging.Client(project=project)\n",
    "\n",
    "for entry in client.list_entries(filter_=pod_filter):\n",
    "  print(entry.payload.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
